variables:
  SCRIPT_PATH: "./services_streaming_lane/test.sh"
  REPO_PATH: "/root/SOURCE_FILES/Quant_Data_Platform/services_streaming_lane"

stages:
  - test_pipeline
  - deploy
  - teardown

test_pipeline:
  stage: test_pipeline
  tags: [master_k3]
  script:
    - set -euo pipefail

    # --- copy required local artifacts into the freshly cloned repo workspace (overwrite only) ---
    - rsync -a ${REPO_PATH}/test_env/.terraform/ services_streaming_lane/test_env/.terraform/
    - rsync -a ${REPO_PATH}/ib_connector/infra_test/gen-ibkr-trust.sh services_streaming_lane/ib_connector/infra_test/gen-ibkr-trust.sh
    - rsync -a ${REPO_PATH}/ib_connector/infra_test/ibkr_client_portal.pem services_streaming_lane/ib_connector/infra_test/ibkr_client_portal.pem
    - rsync -a ${REPO_PATH}/ib_connector/infra_test/ibkr_truststore.jks services_streaming_lane/ib_connector/infra_test/ibkr_truststore.jks
    - rsync -a ${REPO_PATH}/ib_connector/infra_test/ibkr_client_portal.pem services_streaming_lane/ib_connector/source/ibkr_client_portal.pem
    - rsync -a ${REPO_PATH}/ib_connector/infra_test/ibkr_truststore.jks services_streaming_lane/ib_connector/source/ibkr_truststore.jks
    - rsync -a "${REPO_PATH}/spark-3.5.7-bin-hadoop3/" "services_streaming_lane/spark-3.5.7-bin-hadoop3/"

    # --- run the full pipeline sequentially (sleep 5s between steps) ---
    - bash "$SCRIPT_PATH" create_cluster_test
    - sleep 60
    - bash "$SCRIPT_PATH" prepare_env test
    - sleep 30
    - bash "$SCRIPT_PATH" deploy_kafka
    - sleep 10
    - bash "$SCRIPT_PATH" deploy_avro_schema_registry
    - sleep 10
    - bash "$SCRIPT_PATH" deploy_clickhouse
    - sleep 10
    - bash "$SCRIPT_PATH" deploy_spark
    - sleep 10
    - bash "$SCRIPT_PATH" submit_spark_job
    - sleep 10
    - bash "$SCRIPT_PATH" deploy_ib_connector
    - sleep 5
    - sleep 200
    - sleep 5
    - bash "$SCRIPT_PATH" check_clickhouse_ingestion_tables
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_non_kafka_namespaces
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_kafka_namespace
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_cluster_test
    - sleep 10
    - bash "$SCRIPT_PATH" remove_workers_test
  only: [main]

deploy:
  stage: deploy
  tags: [master_k3]
  needs: [test_pipeline]
  script:
    - set -euo pipefail
    - cd /root/SOURCE_FILES/Quant_Data_Platform
    - git pull
  only: [main]

teardown_on_failure:
  stage: teardown
  tags: [master_k3]
  when: on_failure
  allow_failure: true
  script:
    - set +e
    - bash "$SCRIPT_PATH" destroy_namespace_ib
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_namespace_spark
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_namespace_clickhouse
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_namespace_avro
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_kafka_namespace
    - sleep 10
    - bash "$SCRIPT_PATH" destroy_cluster_test
    - sleep 10
    - bash "$SCRIPT_PATH" remove_workers_test
    - exit 0
  only: [main]
